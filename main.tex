% -*- Mode:TeX -*-
% LaTeX template for CinC papers                   v 1.1a 22 August 2010
%
% To use this template successfully, you must have downloaded and unpacked:
%       http://www.cinc.org/authors_kit/papers/latex.tar.gz
% or the same package in zip format:
%       http://www.cinc.org/authors_kit/papers/latex.zip
% See the README included in this package for instructions.
%
% If you have questions, comments or suggestions about this file, please
% send me a note!  George Moody (george@mit.edu)
%
\documentclass[twocolumn]{cinc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}

\begin{document}
\bibliographystyle{cinc}

\title{Multilabel 12-Lead Electrocardiogram Classification Using \\
Gradient Boosting Tree Ensemble}

\author {Alexander W. Wong$^{1}$, Weijie Sun$^{2}$, Sunil V. Kalmady$^{2}$, Padma Kaul$^{2}$, Abram Hindle$^{1}$\\
\ \\
 $^1$ University of Alberta, Edmonton, Canada \\
$^2$ Canadian VIGOUR Centre, Edmonton, Canada }

\maketitle

\newcommand{\officialscore}{{0.476} }

\begin{abstract}

Standard 12-lead electrocardiograms (ECGs) are commonly used to detect cardiac irregularities such as atrial fibrillation, blocks, and irregular complexes.
For the PhysioNet/CinC 2020 Challenge, we built an algorithm using gradient boosted tree ensembles fitted on morphology and signal processing features to classify ECG diagnosis.

For each lead, we derive features from heart rate variability, PQRST template shape, and the full waveform.
We concatenate the features of all 12 leads to fit an ensemble of gradient boosting decision trees to predict probabilities of ECG instances belonging to each class.
We use repeated random sub-sampling by splitting our dataset of 43,101 records into 100 independent runs of 85:15 training/validation splits for our evaluation results.

Our methodology generates an average validation split challenge score of 0.484, with a PhysioNet official phase hold out test set score of \officialscore under the team name, CVC.

\end{abstract}

\section{Introduction}

The electrocardiogram (ECG) is the current "gold standard" strategy for detecting cardiac diseases, outperforming screening history and physical examinations in accuracy and sensitivity~\cite{harmon_effectiveness_2015}.
However, ECG interpretation is a complex task with frequent disagreements between health care staff, with up to a 33\% interpretation error rate~\cite{mele_improving_2008}.
Despite active research in computerized interpretations of ECGs, trained human over-reading and confirmation is required and emphasized in published reports~\cite{schlapfer_computer-interpreted_2017}.

This work classifies standard 12-lead ECGs to their clinical diagnosis as part of the \emph{PhysioNet/CinC 2020 Challenge}~\cite{physionet_challenge_2020}.
We develop a multi-label classification algorithm using entropy and signal processing inspired features and a gradient boosting decision tree ensemble.

\subsection{Dataset \& Scoring Criteria}

The official phase dataset contains a total of 43,101 ECG records.
Each record contains a set of one or more SNOMED CT codes, although not all labels are evaluated in the challenge.
Table~\ref{tab:dataset_labeldx} displays the 27 labels selected for evaluation by the challenge organizers.

\begin{table}[tbp]
  \caption{\label{tab:dataset_labeldx} Labels count and percentage in dataset.}
  \vspace{4 mm}
  \centerline{\begin{tabular}{lrr} \hline
    Diagnosis & Count & \% Total \\ \hline
    1st degree av block & 2394 & 5.6\% \\
    atrial fibrillation & 3475 & 8.0\% \\
    atrial flutter & 314 & 0.7\% \\
    bradycardia & 288 & 0.7\% \\
    complete right bundle branch block & 683 & 1.6\% \\
    incomplete right bundle branch block & 1611 & 3.7\% \\
    left anterior fascicular block & 1806 & 4.2\% \\
    left axis deviation & 6086 & 14.1\% \\
    left bundle branch block & 1041 & 2.4\% \\
    low QRS voltages & 556 & 1.3\% \\
    nonspecific intraventricular conduction & 997 & 2.3\% \\
    pacing rhythm & 299 & 0.7\% \\
    premature atrial contraction & 1729 & 4.0\% \\
    premature ventricular contractions & 188 & 0.4\% \\
    prolonged PR interval & 340 & 0.7\% \\
    prolonged QT interval & 1513 & 3.5\% \\
    Q wave abnormal & 1013 & 2.4\% \\
    right axis deviation & 427 & 1.0\% \\
    right bundle branch block & 2402 & 5.6\% \\
    sinus arrhythmia & 1240 & 2.9\% \\
    sinus bradycardia & 2359 & 5.5\% \\
    sinus rhythm & 20846 & 48.4\% \\
    sinus tachycardia & 2402 & 5.6\% \\
    supraventricular premature beats & 215 & 0.5\% \\
    T wave abnormal & 4673 & 10.8\% \\
    T wave inversion & 1112 & 2.6\% \\
    ventricular premature beats & 365 & 0.8\% \\ \hline
  \end{tabular}}
\end{table}

The objective of this challenge is to maximize the metric: $\sum_{ij} w_{ij} a_{ij}$.
Given a set of diagnoses $C = \{c_i\}$, we compute a confusion matrix $A = [a_{ij}]$ where $a_{ij}$ contains records that are classified as class $c_i$ and belong to class $c_j$.
The weights $W = [w_{ij}]$, shown in Figure~\ref{fig:dataset_labeldx}, are set by the challenge to indicate clinical similarity between classes.

\begin{figure}[ht]
  \centering
  \includegraphics[width=8cm]{fig/label_weights.png}
  \caption{Evaluation scoring function weights per label.}
  \label{fig:dataset_labeldx}
\end{figure}

\section{Methodology}

Our approach is inspired by existing methods which use feature engineering and shallow learning classifiers~\cite{goodwin_classification_2017}.
Figure~\ref{fig:methodology} shows an overview of our learning algorithm pipeline from first cleaning and preprocessing the ECG, to then extracting the full waveform, heartbeat template, and heart rate variability features, finally using these features as input to our binary classifiers.

We rely on the \emph{NeuroKit2} (version \texttt{0.0.40}) neurophysiological signal processing library for ECG signal cleaning, PQRST annotation, signal quality calculation, and heart rate variability metrics~\cite{neurokit2}.
We also use the time series feature extraction library \emph{tsfresh} (version \texttt{0.16.0}) for analysis of the PQRST template and the full waveform~\cite{CHRIST201872}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=7.9cm]{fig/methodology.png}
  \caption{Methodology overview. Feature engineering is performed concurrently for each lead then concatenated.}
  \label{fig:methodology}
\end{figure}

\subsection{Signal Pre-processing}

First we perform signal pre-processing to normalize and clean the raw ECG signal.
Slow drift and DC offset are removed with a Butterworth highpass filter followed by smoothing using a moving average kernel of 0.02 seconds.
Each of the cleaned leads are independently annotated with the PQRST peaks, the PRT onsets, and PRT offsets.

We isolate one candidate heart beat signal for each lead by segmenting heart beat windows as a $-0.35$ to 0.5 second window around each R-peak, shortening to a $-0.25$ to 0.4 second window if the mean heart rate exceeds 80 beats per minute.
We create an ECG signal quality metric by interpolating the distance of each QRS segment from the average QRS segment in the data.
ECG signal quality is therefore relative for each step in the entire length of the signal, where 1 corresponds to beats that are closest to the average QRS and 0 corresponds to beats that are most distant to the average QRS.
We use the PQRST beat window with the highest signal quality as our candidate lead heartbeat template.

\subsection{Feature Engineering}

Our engineered features are categorized as one of three categories.
Full waveform features are derived using the end-to-end ECG signal.
Template features are constructed from the extracted PQRST window during pre-processing.
Heart rate variability features rely on the relative distances between each R-peak.
Each extraction technique is performed independently per lead.

For full waveform and heartbeat template features, we use the cleaned ECG signal and apply the \emph{tsfresh} feature extraction library.
For full waveform features, we cap the signal sampling rate to a maximum of 500Hz before limiting the signal to the middle 2,000 samples to remove starting and trailing artifacts.
% We set the \texttt{ComprehensiveFCParameters} parameter during \emph{tsfresh} feature extraction.
Template features are derived from the isolated heart beat window with highest signal quality.
Using the default feature extraction settings, we generate 763 template and 763 full waveform features per lead.
The extracted features include autoregressive model coefficients, change quantiles, aggregate linear least-squares regression trends, peak counts, sample/approximation entropy, energy, continuous waveform transform coefficients, fast fourier transform coefficients, and other descriptive statistics of the signal.

Heart rate variability (HRV) features are generated from the cleaned signal and corresponding R-peak annotations using \emph{NeuroKit2}.
We use the default feature extraction settings and generate 53 different HRV features per lead.
HRV features include: mean, median, standard/absolute deviation, and interquartile range of the RR intervals; standard deviation of the successive differences between RR intervals; proportion of RR intervals greater than 50/20ms over total RR intervals; and geometric indices measuring triangular interpolation of the RR interval distribution.

For each 12-lead record we combine all three categories of engineered features with the age and sex parsed from the ECG record metadata.
We arrive at a $12 \cdot (763 + 763 + 53) + 2 = 18,950$ length feature vector per 12-lead record.
% For undefined features, such as the HRV feature set on signals where no PQRST annotations could be generated, \texttt{NaN} placeholders are set.

\subsection{Classification}

We train a XGBoost binary classifier for each of the 27 clinical diagnosis, using \texttt{xgboost@1.1.1}~\cite{chen_xgboost_2016}.
% We use the \texttt{gbtree} booster method with the \texttt{gpu\_hist} tree method and \texttt{gradient\_based} sampling method.
% All other model parameters are left to their defaults.
We sample each training instance with a selection probability proportional to the regularized absolute value of the gradients.
Early stopping is set to 20 rounds with binary logistic regression as our objective function.

We use the evaluation scoring weights as instance sample weights, capping positive examples to a 0.5 threshold.
For example, when training the 1st degree atrioventricular block (IAVB) classifier we consider instances of bradycardia (Brady), incomplete right bundle branch block (IRBBB), prolonged PR interval (LPR), sinus arrhythmia (SA), and sinus bradycardia (SB) as positive examples with 0.5 weight.
Other labels that have scoring function weights below 0.5 are treated as negative examples with a sample weight of 1.
To account for the dataset label imbalance, we further scale the positive weight using the number of negative samples over the positive samples in the training set split.
We use repeated random sub-sampling of our total dataset, randomly splitting our 43,101 records into an 85:15 training/validation set split.

We run 100 experiments using the full 18,950 features to determine feature importances.
Feature importance is the model reported gain in accuracy contributed by the feature over all branches in the decision tree.
We average the importances outputted by the 27 classifiers in each experiment to get the mean importance for each feature.
We generate our challenge classification results by running 100 additional experiments, using only the top 1,000 most important features ranked by mean feature importance.

\section{Results}

\begin{figure}[ht]
  \centering
  \includegraphics[width=7.9cm]{fig/top_features_bar.png}
  \caption{Count of lead and feature categories comprising the top 1,000 features. Age, but not sex, is important meta.}
  \label{fig:top_features}
\end{figure}

A categorical visualization of our top 1,000 features, broken down by lead and feature type, is shown in Figure~\ref{fig:top_features}.
We see that heartbeat template features are particularly important, with emphasis on leads \texttt{aVR} and \texttt{V1}.

Our methodology attains a mean challenge metric score of 0.484 on our validation splits.
Additionally, we attain mean values for AUROC of 0.890, AUPRC of 0.390, accuracy of 0.251, overall $\text{F}_1$ score of 0.370, $\text{F}_\beta$ of 0.427, and $\text{G}_\beta$ measure of 0.222 using $\beta = 2$.
An overview of these classification metrics can be found in Figure~\ref{fig:classification_metrics_summary}.

\begin{figure}[hb]
  \centering
  \includegraphics[width=7.9cm]{fig/classification_metrics.png}
  \caption{Summary of classification metrics over 100 experiments on all labels. Annotations indicate mean value.}
  \label{fig:classification_metrics_summary}
\end{figure}

Our model's top three best classified labels are normal sinus rhythm (SNR, $\text{F}_1$ mean: 0.920), left bundle branch block (LBBB, $\text{F}_1$ mean: 0.836), and sinus tachycardia (STach, $\text{F}_1$ mean: 0.779).
A summary of our 100 experiment $\text{F}_1$ scores for each label is in Figure~\ref{fig:f1_score}.

\begin{figure*}[ht]
  \centering
  \includegraphics[width=17.0cm]{fig/label_f1s.png}
  \caption{Label-wise $\text{F}_1$ scores over 100 experiments. Annotations indicate mean value.}
  \label{fig:f1_score}
\end{figure*}

Furthermore, we run a Pearson correlation coefficient test between the label $\text{F}_1$ means and the label counts within our dataset.
The statistical test reveals a Pearson correlation coefficient of 0.599 at a p-value of $9.7 \cdot 10^{-4}$.
This result suggests that a positive linear correlation exists between the label occurrence in our dataset and our classification model's $\text{F}_1$ score.

On the official phase hold out test set, our methodology achieves a challenge score of \officialscore.

\section{Discussion \& Future Work}

Despite the label specific scaling of our dataset, the correlation between the label occurrence with the $\text{F}_1$ scores suggest further improvements are necessary to mitigate label imbalance.
The label imbalance may be addressed by adding more low occurrence disorders into the existing corpus of ECG records.
Synthesizing new records of low occurrence disorders to use as training data may also prove promising.
Additionally, exploration of new features to use as classifier inputs may reveal common characteristics of specific heart disorders that are currently missing.

Our approach, although applicable to 12-lead ECGs, perform feature extraction on each lead separately before concatenating the features together for classification.
We believe that further improvements can be made utilizing feature extraction approaches capable of handling multi-dimensional time series data.

\section{Conclusion}

We create an algorithm for the classification of 27 heart conditions using signal processing inspired feature engineering and an XGBoost tree ensemble classifier.
We combine a set of 18,950 features from full waveform, heartbeat template, and heart rate variability groups.
Using 100 repeated random sub-sampling of 85:15 train/validation, we train models to get feature importances and distilled out 1,000 most important features.
Using this reduced set of 1,000 features, we retrain our models and achieve a mean challenge score of 0.484 on our validation split.
The official phase challenge score on the \emph{PhysioNet/CinC} hold out test set is \officialscore for our team, \emph{CVC}.


\section*{Acknowledgments}
We would like to thank Eric Ly and Leiah Luoma of the Canadian VIGOUR Center for their help and guidance during our research journey.

\bibliography{main}

\begin{correspondence}
Alexander W. Wong\\
Department of Computing Science\\
2-32 Athabasca Hall, University of Alberta\\
Edmonton, Alberta, Canada\\
T6G 2E8\\
alex.wong@ualberta.ca
\end{correspondence}

\end{document}

